Have been running ten concurrent clients uploading wikipedia to hbase.  Each update includes some metadata – URL, mimetype – and the page content.  Caching updates across compactions and splits, we OOME (Default heap size of 1G).  10 concurrent clients are doing over 10k rows a minute.  HBase should be able to carry this common loading scenario.