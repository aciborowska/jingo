There's a hard-coding in HLog#splitLog that presumes we always read in batches of ten logs:



Index: src/java/org/apache/hadoop/hbase/regionserver/HLog.java

===================================================================

--- src/java/org/apache/hadoop/hbase/regionserver/HLog.java     (revision 799653)

+++ src/java/org/apache/hadoop/hbase/regionserver/HLog.java     (working copy)

@@ -860,7 +860,7 @@

         // Stop at logfiles.length when it's the last step

         int endIndex = step == maxSteps - 1? logfiles.length: 

           step * concurrentLogReads + concurrentLogReads;

-        for (int i = (step * 10); i < endIndex; i++) {

+        for (int i = (step * concurrentLogReads); i < endIndex; i++) {

           // Check for possibly empty file. With appends, currently Hadoop 

           // reports a zero length even if the file has been sync'd. Revisit if

           // HADOOP-4751 is committed.



When I changed it so we default to reading 3 files at a time rather than 10 over in hbase-1683, the hard-coding made it so we didn't read all logs.