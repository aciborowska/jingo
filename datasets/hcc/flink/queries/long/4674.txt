File descriptors utilized by Flink Task Manager are not released even after completion of job.
For releasing all file descriptors, we need to reboot the flink cluster. This causes all Jobs to run succesfully until the OS limit is hit and post which Job keeps failing - 

Error on Flink - 

java.io.IOException: Error opening the Input Split file:/data/Temp/RUN10_1000.csv [84950,1699]: /data/Temp/RUN10_1000.csv (Too many open files)
	at org.apache.flink.api.common.io.FileInputFormat.open(FileInputFormat.java:682)
	at org.apache.flink.api.common.io.DelimitedInputFormat.open(DelimitedInputFormat.java:411)
	at org.apache.flink.api.common.io.DelimitedInputFormat.open(DelimitedInputFormat.java:45)
	at org.apache.flink.runtime.operators.DataSourceTask.invoke(DataSourceTask.java:147)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:559)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: /data/Temp/RUN10_1000.csv (Too many open files)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.flink.core.fs.local.LocalDataInputStream.<init>(LocalDataInputStream.java:52)
	at org.apache.flink.core.fs.local.LocalFileSystem.open(LocalFileSystem.java:143)
	at org.apache.flink.api.common.io.FileInputFormat$InputSplitOpenThread.run(FileInputFormat.java:842)