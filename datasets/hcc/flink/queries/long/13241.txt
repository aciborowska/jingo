In the case that a job allocates a few slots first and after a period allocates some other slots. The YarnResourceManager seems to receive and ignore the latter slot requests.

To produce this issue, we can create a job with 2 vertices in different shared groups, as shown below:



Slot allocation for map2 vertex happens after the source vertex acquires slots to decide its location, thus to meet the input constraints.

YarnResourceManager can receive slot requests for map2, but seems not to handle it and the job will hang there waiting for resources.

In my observation, this issue does not happen on Flink(Version: 1.9-SNAPSHOT, Rev:3bc322a, Date:26.06.2019 @ 17:28:51 CST). It should be a new issue after that.

 