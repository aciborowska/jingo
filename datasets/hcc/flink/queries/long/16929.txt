 We have a Flink job which keyBys session ID (sId), and uses a session window with 30 minutes gap:


inputStream
    .keyBy(keySelector)
    .window(EventTimeSessionWindows.withGap(Time.minutes(30)))
    .allowedLateness(Time.seconds(0L))


This Flink job reads from Kinesis stream.

Lately (I suspect after upgrading from 1.5.4 to 1.9.1) we get too many sessions, with gaps of several seconds (instead of 30 minutes).

We have no idea why it's happening and suspect a Flink bug or a state backend bug (we use RocksDB).

I haven't found any indication in the logs except for some read throughput warnings which were resolved by a backoff.

Attached is a table of derived sessions, and then the raw events

Sessions

  

 

Events

 

   

 

 

 

 