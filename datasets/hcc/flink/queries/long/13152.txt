

ERROR [2019-07-08 22:09:22,200] ({ParallelScheduler-Worker-1} FlinkSqlInterrpeter.java[runSqlList]:107) - Fail to run sql:select * from a
org.apache.flink.table.api.TableException: Cannot generate a valid execution plan for the given query:

FlinkLogicalTableSourceScan(table=[[hive, default, a]], fields=[tt], source=[HiveTableSource(tt)])

This exception indicates that the query uses an unsupported SQL feature.
Please check the documentation for the set of currently supported SQL features.
at org.apache.flink.table.plan.Optimizer.runVolcanoPlanner(Optimizer.scala:245)
at org.apache.flink.table.plan.Optimizer.optimizePhysicalPlan(Optimizer.scala:170)
at org.apache.flink.table.plan.BatchOptimizer.optimize(BatchOptimizer.scala:57)
at org.apache.flink.table.api.internal.BatchTableEnvImpl.translate(BatchTableEnvImpl.scala:258)
at org.apache.flink.table.api.scala.internal.BatchTableEnvironmentImpl.toDataSet(BatchTableEnvironmentImpl.scala:66)

This is the exception I hit, and the below is code to reproduce the issue.

I suspect it is because I am using DataSet and HiveCatalog together



def showTable(table: Table): String = {
  val columnNames: Array[String] = table.getSchema.getFieldNames
  val dsRow: DataSet[Row] = btenv.toDataSet[Row](table)
  val rows = dsRow.first(maxResult).collect()
}

 