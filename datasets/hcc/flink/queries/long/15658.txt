summary:
The same sql can run in a batch environment normally,  but in a streaming environment there will be a exception like this:
[ERROR] Could not execute SQL statement. Reason:
org.apache.flink.table.api.ValidationException: Field names must be unique. Found duplicates: [f1]





The sql is:

CREATE TABLE `tenk1` (
	unique1 int,
	unique2 int,
	two int,
	four int,
	ten int,
	twenty int,
	hundred int,
	thousand int,
	twothousand int,
	fivethous int,
	tenthous int,
	odd int,
	even int,
	stringu1 varchar,
	stringu2 varchar,
	string4 varchar
) WITH (
	'connector.path'='/daily_regression_test_stream_postgres_1.10/test_join/sources/tenk1.csv',
	'format.empty-column-as-null'='true',
	'format.field-delimiter'='|',
	'connector.type'='filesystem',
	'format.derive-schema'='true',
	'format.type'='csv'
);

CREATE TABLE `int4_tbl` (
	f1 INT
) WITH (
	'connector.path'='/daily_regression_test_stream_postgres_1.10/test_join/sources/int4_tbl.csv',
	'format.empty-column-as-null'='true',
	'format.field-delimiter'='|',
	'connector.type'='filesystem',
	'format.derive-schema'='true',
	'format.type'='csv'
);

select a.f1, b.f1, t.thousand, t.tenthous from
  tenk1 t,
  (select sum(f1)+1 as f1 from int4_tbl i4a) a,
  (select sum(f1) as f1 from int4_tbl i4b) b
where b.f1 = t.thousand and a.f1 = b.f1 and (a.f1+b.f1+999) = t.tenthous;




