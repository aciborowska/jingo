Here's sql I used.


insert into sink_kafka select status, direction, cast(event_ts/1000000000 as timestamp(3)) from source_kafka where status <> 'foo';
insert into sink_kafka2 select status, direction, cast(event_ts/1000000000 as timestamp(3)) from source_kafka where status <> 'foo';
 

Ideally flink should run these 2 sql as one dag with 2 sinks, but what I see is that flink won't merge them into one dag.

