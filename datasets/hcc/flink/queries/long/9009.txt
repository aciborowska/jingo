Steps to reproduce:

1- Flink with Kafka as a consumer -> Writing stream to Cassandra using flink cassandra sink.

2- In memory Job manager and task manager with checkpointing 5000ms.

3- env.setpararllelism(10)-> As kafka topic has 10 partition.

4- There are around 13 unique streams in a single flink run time environment which are reading from kafka -> processing and writing to cassandra.

Hardware: CPU 200 milli core . It is deployed on Paas platform on one node

Memory: 526 MB.

 

When i start the server, It starts flink and all off sudden stops with above error. It also shows out of memory error.

 

It would be nice if any body can suggest if something is wrong.

 

Maven:

flink-connector-cassandra_2.11: 1.3.2

flink-streaming-java_2.11: 1.4.0

flink-connector-kafka-0.11_2.11:1.4.0

 

 

 