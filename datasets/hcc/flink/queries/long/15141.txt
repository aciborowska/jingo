The planner what I used is blink.

The source table is:
CREATE TABLE `aggtest` (
    a smallint,
    b float
) WITH (
    'format.field-delimiter'='|',
    'connector.type'='filesystem',
    'format.derive-schema'='true',
    'connector.path'='hdfs://zthdev/defender_test_data/daily/test_aggregates/sources/aggtest.csv',
    'format.type'='csv'
); 
 

The sink table is:
CREATE TABLE `agg_decimal_res` (
    avg_107_943 DECIMAL(10, 3)
) WITH (
    'format.field-delimiter'='|',
    'connector.type'='filesystem',
    'format.derive-schema'='true',
    'connector.path'='hdfs://zthdev/defender_test_data/daily/test_aggregates/test_aggregates__test_avg_cast_batch/results/agg_decimal_res.csv',
    'format.type'='csv'
);
 

The sql is:

INSERT INTO agg_decimal_res SELECT CAST(avg(b) AS numeric(10,3)) AS avg_107_943 FROM aggtest;

 

After execute the sql, there will be a exception appear, just like this:

[INFO] Submitting SQL update statement to the cluster...
 [ERROR] Could not execute SQL statement. Reason:
 org.apache.flink.table.api.ValidationException: Field types of query result and registered TableSink `default_catalog`.`default_database`.`agg_decimal_res1` do not match.
 Query result schema: [avg_107_943: DECIMAL(10, 3)]
 TableSink schema: [avg_107_943: DECIMAL(38, 18)]

 