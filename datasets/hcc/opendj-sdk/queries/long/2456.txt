Found using OpenDJ 3.0.0 (rev R4b6eae2b88b5a5abc3bc7bcee205ecf033675a0f).

We had this problem multiple times during the functional tests.

The problem happened during tests on a replicated topology in which we check that changes applied in  the schema (99-user.ldif) are correctly replicated.
More precisly after restart of one server of the replicated topology.


$ ./DJ1/opendj/bin/stop-ds
$ ./DJ1/opendj/bin/start-ds
[22/Nov/2015:13:30:17 +0000] category=EXTENSIONS severity=NOTICE msgID=org.opends.messages.extension.571 msg=Loaded extension from file '/home/testuser/replication_group/Schema/DJ1/opendj/lib/extensions/snmp-mib2605.jar' (build 3.0.0-SNAPSHOT, revision 4b6eae2b88b5a5abc3bc7bcee205ecf033675a0f)
[22/Nov/2015:13:30:17 +0000] category=CORE severity=NOTICE msgID=org.opends.messages.core.134 msg=OpenDJ 3.0.0-SNAPSHOT (build 20151122013516, R4b6eae2b88b5a5abc3bc7bcee205ecf033675a0f) starting up
[22/Nov/2015:13:30:19 +0000] category=UTIL severity=NOTICE msgID=org.opends.messages.runtime.21 msg=Installation Directory:  /home/testuser/replication_group/Schema/DJ1/opendj
[22/Nov/2015:13:30:19 +0000] category=UTIL severity=NOTICE msgID=org.opends.messages.runtime.23 msg=Instance Directory:      /home/testuser/replication_group/Schema/DJ1/opendj
[22/Nov/2015:13:30:19 +0000] category=UTIL severity=NOTICE msgID=org.opends.messages.runtime.17 msg=JVM Information: 1.7.0_79-b15 by Oracle Corporation, 64-bit architecture, 922746880 bytes heap size
[22/Nov/2015:13:30:19 +0000] category=UTIL severity=NOTICE msgID=org.opends.messages.runtime.18 msg=JVM Host: myhost.example.com, running Linux 3.13.0-62-generic amd64, 4145373184 bytes physical memory size, number of processors available 2
[22/Nov/2015:13:30:19 +0000] category=UTIL severity=NOTICE msgID=org.opends.messages.runtime.19 msg=JVM Arguments: "-Dorg.opends.server.scriptName=start-ds"
[22/Nov/2015:13:30:21 +0000] category=PLUGGABLE severity=NOTICE msgID=org.opends.messages.backend.513 msg=The database backend userRoot containing 166 entries has started
[22/Nov/2015:13:30:21 +0000] category=EXTENSIONS severity=NOTICE msgID=org.opends.messages.extension.221 msg=DIGEST-MD5 SASL mechanism using a server fully qualified domain name of: myhost.example.com
[22/Nov/2015:13:30:21 +0000] category=SYNC severity=NOTICE msgID=org.opends.messages.replication.204 msg=Replication server RS(2101) started listening for new connections on address 0.0.0.0 port 9063
[22/Nov/2015:13:30:21 +0000] category=CORE severity=NOTICE msgID=org.opends.messages.core.139 msg=The Directory Server has sent an alert notification generated by class org.opends.server.core.DirectoryServer (alert type org.opends.server.DirectoryServerShutdown, alert ID org.opends.messages.core-141): The Directory Server has started the shutdown process. The shutdown was initiated by an instance of class org.opends.server.core.DirectoryServer and the reason provided for the shutdown was An error occurred while trying to start the Directory Server: An error occurred while attempting to initialize the Directory Server synchronization provider referenced in configuration entry org.opends.server.replication.plugin.MultimasterReplication: cn=Multimaster Synchronization,cn=Synchronization Providers,cn=config null
[22/Nov/2015:13:30:22 +0000] category=CORE severity=WARNING msgID=org.opends.messages.core.342 msg=An error occurred while attempting to release a shared lock for backend changelog: The attempt to release the lock held on /home/testuser/replication_group/Schema/DJ1/opendj/locks/backend-changelog.lock failed because no record of a lock on that file was found. This lock should be automatically cleaned when the Directory Server process exits, so no additional action should be necessary
[22/Nov/2015:13:30:22 +0000] category=PLUGGABLE severity=NOTICE msgID=org.opends.messages.backend.370 msg=The backend userRoot is now taken offline
[22/Nov/2015:13:30:22 +0000] category=CORE severity=NOTICE msgID=org.opends.messages.core.203 msg=The Directory Server is now stopped
WARNING:  The following threads were still active after waiting up to 60 seconds for them to stop:
Thread Name:  Replica replay thread 0
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 1
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 2
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 3
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 4
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 5
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 6
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 7
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 8
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

Thread Name:  Replica replay thread 9
Stack Trace:
              sun.misc.Unsafe.park(Unsafe.java:native method)

              java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)

              java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)

              java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)

              org.opends.server.replication.plugin.ReplayThread.run(ReplayThread.java:92)

The timeout of '200' seconds to start the server has been reached.  You can
use the argument '--timeout' to increase this timeout

