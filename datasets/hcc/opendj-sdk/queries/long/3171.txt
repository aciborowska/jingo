The current off-heap memory availability checking (based on OOME) doesn't work when the underlying system is able to handle memory request greater than the amount of RAM available: the ByteBuffer.allocateDirect() succeed even when no more free memory is available.

The over-provisioning of this memory trigger the Linux's OOM killer which is killing the process responsible of consuming all this RAM (in this case, DJ).

A workaround is to fix an artificial limit of the amount of direct memory available to the JVM using DirectMemorySize directive (i.e: -XX:DirectMemorySize=128M). This will make allocateDirect() throw OOME once these 128Mb are already allocated.

A more future-proof solution would be to check the amount of free memory available to ensure that we're not over-allocating memory. Since this information requires the usage of non-standard API, we should fallback to on-heap mechanism if we can't get it.