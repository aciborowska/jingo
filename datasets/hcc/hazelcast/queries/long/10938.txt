Local statistics uses milliseconds for get/put/remove latencies. It is very usual for latencies to be around microseconds, hence the values may become 0 very easily. Especially the accumulative statistics such as totalGetLatencies and such, it does not make sense to stay at 0 even though there are millions of gets each below millisecond latency.

E.g. Our get latency for a single get is usually in microseconds around 100-200usecs. If you do 1 million get, then we normally expect the latency to be 1 million * 200 usec=200 sec. But since latency for each request is less than a millisecond, it is recorded as to be zero and the total becomes zero.