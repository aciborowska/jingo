We ran a series of scale tests with Hazelcast 3.7.3 cluster and noticed a strange thing.

Background:
Two maps in the cluster, 1M entries each. Multiple load test clients invoke the same operation on randomly selected entries. Each operation involves invocation of two EntryProcessors, one on each map.
(Initially dataset is empty, but these EntryProcessors when invoked create an entry if it does not exist yet)

1. started with 15 node cluster
2. put that cluster under load, let it stabilise measured requests per second across all the clients. 89K op/sec
3. reduced cluster size to 12. This caused some loss of data as no backups were used but those repetitive operations from clients effectively re-create the same entries so it will be back to 1M after some time
4. let it stabilise again and measured total throughput of test clients. No surprise here, it dropped to 64K op/sec.
5. Grew cluster back to 15 nodes
6. let it stabilise again and measured total throughput again. 77K op/sec

Now, the last bit is a bit surprising because cluster performance never returned to its original level.
We do not understand reason for this because there is no noticeable imbalance in CPU utilisation across these nodes. Nor there is significant imbalance in how dataset is partitioned.

To be frank, our setup is a bit more involved than described as there is a RESTful web service between client and Hazelcast. This extra step should explain to you initial 89K/sec in case you expected more from cluster of that size. Obviously web service adds some latency but it is absolutely stateless thing - when you make HTTP call to it, it just immediately makes a call to Hazelcast and does nothing more. And we put a huge cluster of these web servers - way more than needed to handle the volume we had. And during the experiment we did not touch these web servers, only played with number of Hazelcast servers.

Creating an isolated test seems to be a lot of effort so before doing anything like that I would really like to:
* get your feedback on that - maybe you already encountered similar issue before and know what can be causing it
* check if you already have such (or a similar) test

Cheers