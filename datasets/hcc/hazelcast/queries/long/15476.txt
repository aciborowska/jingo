We have a cluster of two nodes running 3.11.1 (on EC2 instances running kernel 4.15.0-1045-aws #47-Ubuntu SMP), which we use in combination with spring cache. We noticed on several occasions that restarting one of the nodes leads to 'corruption' on one of the maps; without logging any errors or exceptions, those particular caches are not being filled properly - all subsequent invocations to the cached methods go through our back-end, without their result being put in te cache. The issue can then only be resolved by either `m.destroy`ing that map, or restarting both hazelcast nodes.

I added snippets of our configuration and relevant log files:

[hazelcast01-config.txt](https://github.com/hazelcast/hazelcast/files/3525024/hazelcast01-config.txt)
[hazelcast02-config.txt](https://github.com/hazelcast/hazelcast/files/3525040/hazelcast02-config.txt)
[hazelcast01-log.txt](https://github.com/hazelcast/hazelcast/files/3525298/hazelcast01-log.txt)
[hazelcast02-log.txt](https://github.com/hazelcast/hazelcast/files/3525299/hazelcast02-log.txt)


