I had a node (call it `nodeB`) that was joining to cluster, consisting of one another node, call it `nodeA`, so cluster initially had 1 member. During join, I had this exception logged:

```
jvm 1    | 2016-08-17 11:58:45,643+0200 INFO  [hz._hzInstance_1_hzgroup.IO.thread-Acceptor] *SYSTEM com.hazelcast.nio.tcp.SocketAcceptorThread - [127.0.0.1]:5701 [hzgroup] [3.6.4] Accepting socket connection from /127.0.0.1:51890
jvm 1    | 2016-08-17 11:58:45,643+0200 INFO  [cached7] *SYSTEM com.hazelcast.nio.tcp.TcpIpConnectionManager - [127.0.0.1]:5701 [hzgroup] [3.6.4] Established socket connection between /127.0.0.1:5701 and /127.0.0.1:51890
jvm 1    | 2016-08-17 11:58:47,995+0200 INFO  [hz._hzInstance_1_hzgroup.migration] *SYSTEM com.hazelcast.partition.InternalPartitionService - [127.0.0.1]:5701 [hzgroup] [3.6.4] Partition balance is ok, no need to re-partition cluster data... 
jvm 1    | 2016-08-17 11:58:51,655+0200 INFO  [hz._hzInstance_1_hzgroup.generic-operation.thread-2] *SYSTEM com.hazelcast.cluster.ClusterService - [127.0.0.1]:5701 [hzgroup] [3.6.4] 
jvm 1    | 
jvm 1    | Members [2] {
jvm 1    |  Member [127.0.0.1]:5701 this
jvm 1    |  Member [127.0.0.1]:5702
jvm 1    | }
jvm 1    | 
jvm 1    | 2016-08-17 11:58:51,765+0200 INFO  [hz._hzInstance_1_hzgroup.migration] *SYSTEM com.hazelcast.partition.InternalPartitionService - [127.0.0.1]:5701 [hzgroup] [3.6.4] Re-partitioning cluster data... Migration queue size: 135
jvm 1    | 2016-08-17 11:58:52,051+0200 WARN  [hz._hzInstance_1_hzgroup.partition-operation.thread-7] *SYSTEM com.hazelcast.partition.impl.ReplicaSyncRequest - [127.0.0.1]:5701 [hzgroup] [3.6.4] null
jvm 1    | java.lang.NullPointerException: null
jvm 1    |  at com.hazelcast.concurrent.atomiclong.AtomicLongService.prepareReplicationOperation(AtomicLongService.java:106) ~[hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.partition.impl.ReplicaSyncRequest.createReplicationOperations(ReplicaSyncRequest.java:150) ~[hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.partition.impl.ReplicaSyncRequest.run(ReplicaSyncRequest.java:82) ~[hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.run(OperationRunnerImpl.java:172) [hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.run(OperationRunnerImpl.java:393) [hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.spi.impl.operationexecutor.classic.OperationThread.processPacket(OperationThread.java:184) [hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.spi.impl.operationexecutor.classic.OperationThread.process(OperationThread.java:137) [hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.spi.impl.operationexecutor.classic.OperationThread.doRun(OperationThread.java:124) [hazelcast-3.6.4.jar:3.6.4]
jvm 1    |  at com.hazelcast.spi.impl.operationexecutor.classic.OperationThread.run(OperationThread.java:99) [hazelcast-3.6.4.jar:3.6.4]
jvm 1    | 2016-08-17 11:58:53,094+0200 INFO  [hz._hzInstance_1_hzgroup.migration] *SYSTEM com.hazelcast.partition.InternalPartitionService - [127.0.0.1]:5701 [hzgroup] [3.6.4] All migration tasks have been completed, queues are empty.
```

My assumption is that this was an IAtomicLong, that `nodeA` removed (invoked `IAtomicLong.destroy()`) during replication, while `nodeB` was joining.

Hazelcast version: 3.6.4
Java: Oracle Java8
OS: dev OSX, prod Linux
