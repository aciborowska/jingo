The test: 
- Server defines a map with an eviction max size policy of “USED_HEAP_SIZE” with a limit far below the max heap size (200 MB in this case). Set in-memory format to BINARY as needed for this eviction size policy. Set eviction policy to LRU. 
- Client repeatedly “set”s objects into the map for different keys. These objects start small and increase in size. Max size is 10 MB, so far smaller than the eviction policy size limit. 
- Once eviction policy limit is reached, the map size appears to increase with each “set” even though some eviction occurs. Eventually this leads to an OOME.

```
Config config = new Config();

String mapName = "map";
config.getMapConfig(mapName).setMaxSizeConfig(new MaxSizeConfig(200, MaxSizeConfig.MaxSizePolicy.USED_HEAP_SIZE)) // 200 MB eviction policy limit with "USED_HEAP_SIZE" mode.
        .setInMemoryFormat(InMemoryFormat.BINARY) // According to documentation this is required for USED_HEAP_SIZE.
        .setEvictionPolicy(EvictionPolicy.LRU);

HazelcastInstance hazelcastInstance = Hazelcast.newHazelcastInstance(config);

IMap<Integer, byte[]> map = hazelcastInstance.getMap(mapName);
int maxSizeBytes = 10 * 1024 * 1024; // 10 MBytes - This is just so that we know the cached values are individually far smaller than the eviction policy limit.  Test case fails before hitting this size anyway.
for (int i = 0; i < maxSizeBytes; i++) {
    map.set(i, new byte[i]);
    if (i % 1000 == 0) {
        System.out.println("Done " + i + " set operations");
    }
}
```
