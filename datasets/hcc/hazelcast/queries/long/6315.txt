Recently I moved to ReplicationMap for one of my caches. Now I see the following exception in app log time to time:

<code>
2015-09-29 16:32:33.045 [cached11] WARN  com.hazelcast.partition.InternalPartitionService - [xxx.xxx.143.53]:10500 [default] [3.5.2] Exception while getting future
java.util.concurrent.TimeoutException: Call Invocation{ serviceName='hz:core:partitionService', op=com.hazelcast.partition.impl.IsReplicaVersionSync{serviceName='hz:core:partitionService', partitionId=67, callId=2055940, invocationTime=1443529943044, waitTimeout=-1, callTimeout=60000}, partitionId=67, replicaIndex=1, tryCount=3, tryPauseMillis=250, invokeCount=1, callTimeout=60000, target=Address[xxx.xxx.143.243]:10500, backupsExpected=0, backupsCompleted=0} encountered a timeout
    at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.resolveApplicationResponse(InvocationFuture.java:366) ~[hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.resolveApplicationResponseOrThrowException(InvocationFuture.java:334) ~[hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.get(InvocationFuture.java:225) ~[hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.partition.impl.InternalPartitionServiceImpl.getFutureResult(InternalPartitionServiceImpl.java:1124) [hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.partition.impl.InternalPartitionServiceImpl.isReplicaInSyncState(InternalPartitionServiceImpl.java:1108) [hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.partition.impl.InternalPartitionServiceImpl.getMemberState(InternalPartitionServiceImpl.java:1049) [hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.partition.impl.InternalPartitionServiceImpl.isMemberStateSafe(InternalPartitionServiceImpl.java:1035) [hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.partition.PartitionServiceProxy.isLocalMemberSafe(PartitionServiceProxy.java:157) [hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.internal.management.TimedMemberStateFactory$1.run(TimedMemberStateFactory.java:91) [hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.util.executor.CachedExecutorServiceDelegate$Worker.run(CachedExecutorServiceDelegate.java:209) [hazelcast-all-3.5.2.jar:3.5.2]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_71]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_71]
    at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]
    at com.hazelcast.util.executor.HazelcastManagedThread.executeRun(HazelcastManagedThread.java:76) [hazelcast-all-3.5.2.jar:3.5.2]
    at com.hazelcast.util.executor.HazelcastManagedThread.run(HazelcastManagedThread.java:92) [hazelcast-all-3.5.2.jar:3.5.2]
</code>

The cache is used as read-mostly, there are 100s..1000s of reads per sec. The cache contains two entries only.
A cluster of 4 members was formed at:

2015-09-29 15:53:57.647 [hz.default.generic-operation.thread-1] INFO  com.hazelcast.cluster.ClusterService - [xxx.xxx.143.53]:10500 [default] [3.5.2] 

Members [4] {
    Member [xxx.xxx.143.8]:10500
    Member [xxx.xxx.143.53]:10500 this
    Member [xxx.xxx.143.9]:10500
    Member [xxx.xxx.143.243]:10500
}

The cache is populated with data. The two entries were added in replicated cache at 16:00 as the latest. Then a number of load/stress tests were performed aginst the system. 

Any ideas on how to prevent this issue?

Thanks, Denis.
