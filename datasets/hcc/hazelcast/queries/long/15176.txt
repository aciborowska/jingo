Hi,
I would like to report an issue which is kind of a scifi, please see following logs to see what happened during and after 4 minute-long network disconnection of a member.
We discovered potentially risky code and I want to discuss with you whether our suggested fix would repair it or not..

Hazelcast version: 3.10.2
Cluster size: 3
  10.80.32.241
  10.80.32.23
  10.80.32.29 this (network disconnection between ~13:57 - ~14:01)
Number of the clients: 0
java: 1.8.152
OS: All members have Windows 10 (no virtual)

hazelcast configuration:
```
hazelcast.heartbeat.interval.seconds=1
hazelcast.connection.monitor.max.faults=1
hazelcast.max.no.heartbeat.seconds=10
hazelcast.wait.seconds.before.join=1
hazelcast.max.wait.seconds.before.join=3
hazelcast.member.list.publish.interval.seconds=10
hazelcast.merge.first.run.delay.seconds=1
hazelcast.merge.next.run.delay.seconds=5
hazelcast.connect.all.wait.seconds=2147483647
hazelcast.max.join.seconds=2147483647
hazelcast.icmp.enabled=true
hazelcast.icmp.timeout=1000
hazelcast.health.monitoring.level=NOISY
hazelcast.health.monitoring.delay.seconds=30
hazelcast.phone.home.enabled=false
hazelcast.jmx=true
```

Logs:

```
2019-06-13 13:56:51.975 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Connecting to /10.80.32.23:5701, timeout: 0, bind-any: true
2019-06-13 13:56:51.975 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Connecting to /10.80.32.241:5701, timeout: 0, bind-any: true
2019-06-13 13:56:51.976 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Could not connect to: /10.80.32.23:5701. Reason: SocketException[No route to host: connect to address /10.80.32.23:5701]
2019-06-13 13:56:51.976 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Could not connect to: /10.80.32.241:5701. Reason: SocketException[No route to host: connect to address /10.80.32.241:5701]
2019-06-13 13:56:52.077 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Connecting to /10.80.32.241:5701, timeout: 0, bind-any: true
2019-06-13 13:56:52.077 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Connecting to /10.80.32.23:5701, timeout: 0, bind-any: true
2019-06-13 13:56:52.077 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Could not connect to: /10.80.32.241:5701. Reason: SocketException[No route to host: connect to address /10.80.32.241:5701]
2019-06-13 13:56:52.077 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Could not connect to: /10.80.32.23:5701. Reason: SocketException[No route to host: connect to address /10.80.32.23:5701]
2019-06-13 13:56:52.077 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.nio.tcp.TcpIpConnectionErrorHandler - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Removing connection to endpoint [10.80.32.241]:5701 Cause => java.net.SocketException {No route to host: connect to address /10.80.32.241:5701}, Error-Count: 3
2019-06-13 13:56:52.077 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] com.hazelcast.nio.tcp.TcpIpConnectionErrorHandler - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Removing connection to endpoint [10.80.32.23]:5701 Cause => java.net.SocketException {No route to host: connect to address /10.80.32.23:5701}, Error-Count: 3
2019-06-13 13:56:52.081 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.MembershipManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Removing Member [10.80.32.241]:5701 - f676dee2-8477-4da7-9054-5f76a55e4743
2019-06-13 13:56:52.081 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-3] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Connecting to /10.80.32.23:5701, timeout: 0, bind-any: true
2019-06-13 13:56:52.082 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-3] com.hazelcast.nio.tcp.TcpIpConnector - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Could not connect to: /10.80.32.23:5701. Reason: SocketException[No route to host: connect to address /10.80.32.23:5701]
2019-06-13 13:56:52.084 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.ClusterService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] 

Members {size:2, ver:4} [
	Member [10.80.32.29]:5701 - 3e137638-ea21-41b5-98da-9665bfef59c4 this
	Member [10.80.32.23]:5701 - 0e930aa5-4951-4de7-9e75-31a6857c9760
]

2019-06-13 13:56:52.084 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] com.hazelcast.internal.cluster.impl.MembershipManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Removing Member [10.80.32.23]:5701 - 0e930aa5-4951-4de7-9e75-31a6857c9760
2019-06-13 13:56:52.085 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] com.hazelcast.internal.cluster.ClusterService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] 

Members {size:1, ver:5} [
	Member [10.80.32.29]:5701 - 3e137638-ea21-41b5-98da-9665bfef59c4 this
]

2019-06-13 13:56:52.085 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.event-4] net.gmc.nuc.core.datagrid.hzl.runtime.HazelcastMembershipListener - Hazelcast cluster membership event occurred. Event: MembershipEvent {member=Member [10.80.32.241]:5701 - f676dee2-8477-4da7-9054-5f76a55e4743,type=removed}. Quorum present: false. Current members: [Member [10.80.32.29]:5701 - 3e137638-ea21-41b5-98da-9665bfef59c4 this]. Quorum size: 2. Member: [Member [10.80.32.241]:5701 - f676dee2-8477-4da7-9054-5f76a55e4743]
2019-06-13 13:56:52.118 +02:00 DEBUG [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.event-4] net.gmc.nuc.core.datagrid.hzl.runtime.HazelcastMembershipListener - Hazelcast cluster node down event sent.
2019-06-13 13:56:52.119 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.event-4] net.gmc.nuc.core.datagrid.hzl.runtime.HazelcastMembershipListener - Hazelcast cluster membership event occurred. Event: MembershipEvent {member=Member [10.80.32.23]:5701 - 0e930aa5-4951-4de7-9e75-31a6857c9760,type=removed}. Quorum present: false. Current members: [Member [10.80.32.29]:5701 - 3e137638-ea21-41b5-98da-9665bfef59c4 this]. Quorum size: 2. Member: [Member [10.80.32.23]:5701 - 0e930aa5-4951-4de7-9e75-31a6857c9760]
2019-06-13 13:56:52.119 +02:00 DEBUG [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.event-4] net.gmc.nuc.core.datagrid.hzl.runtime.HazelcastMembershipListener - Hazelcast cluster node down event sent.
2019-06-13 13:56:52.130 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] net.gmc.nuc.core.datagrid.hzl.runtime.HazelcastQuorumFunction - Applying quorum function
2019-06-13 13:56:52.130 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-8] com.hazelcast.transaction.TransactionManagerService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Committing/rolling-back alive transactions of Member [10.80.32.241]:5701 - f676dee2-8477-4da7-9054-5f76a55e4743, UUID: f676dee2-8477-4da7-9054-5f76a55e4743
2019-06-13 13:56:52.131 +02:00 DEBUG [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-2] net.gmc.nuc.core.db.DirectDatabaseConnector - Creating database connection.
2019-06-13 13:56:52.136 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-8] com.hazelcast.transaction.TransactionManagerService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Committing/rolling-back alive transactions of Member [10.80.32.23]:5701 - 0e930aa5-4951-4de7-9e75-31a6857c9760, UUID: 0e930aa5-4951-4de7-9e75-31a6857c9760
2019-06-13 13:56:52.147 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.generic-operation.thread-1] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Following unknown addresses are found in partition table sent from master[[10.80.32.29]:5701]. (Probably they have recently joined or left the cluster.) {
	[10.80.32.23]:5701
}
2019-06-13 13:56:52.148 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.migration] com.hazelcast.internal.partition.impl.MigrationManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Destination [10.80.32.23]:5701 is not member anymore

2019-06-13 13:57:10.175 +02:00 ERROR [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.migration] com.hazelcast.internal.partition.impl.MigrationManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Promotion commit to [10.80.32.29]:5701 failed for 134 migrations
java.util.concurrent.ExecutionException: PromotionCommitOperation got rejected before execution due to not starting within the operation-call-timeout of: 10000 ms. Current time: 2019-06-13 13:57:10.175. Start time: 2019-06-13 13:56:52.149. Total elapsed time: 18026 ms. Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=848844211, partitionId=-1, replicaIndex=0, callId=-27730, invocationTime=1560427012149 (2019-06-13 13:56:52.149), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=1, callTimeoutMillis=10000, firstInvocationTimeMs=1560427012149, firstInvocationTime='2019-06-13 13:56:52.149', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}
	at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.newOperationTimeoutException(InvocationFuture.java:164)
	at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.resolve(InvocationFuture.java:104)
	at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.resolveAndThrowIfException(InvocationFuture.java:79)
	at com.hazelcast.spi.impl.AbstractInvocationFuture.get(AbstractInvocationFuture.java:162)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.commitPromotionsToDestination(MigrationManager.java:1349)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.commitPromotionMigrations(MigrationManager.java:1229)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.promoteBackupsForMissingOwners(MigrationManager.java:1215)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.run(MigrationManager.java:1156)
	at com.hazelcast.internal.partition.impl.MigrationThread.processTask(MigrationThread.java:121)
	at com.hazelcast.internal.partition.impl.MigrationThread.doRun(MigrationThread.java:98)
	at com.hazelcast.internal.partition.impl.MigrationThread.run(MigrationThread.java:67)
Caused by: com.hazelcast.core.OperationTimeoutException: PromotionCommitOperation got rejected before execution due to not starting within the operation-call-timeout of: 10000 ms. Current time: 2019-06-13 13:57:10.175. Start time: 2019-06-13 13:56:52.149. Total elapsed time: 18026 ms. Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=848844211, partitionId=-1, replicaIndex=0, callId=-27730, invocationTime=1560427012149 (2019-06-13 13:56:52.149), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=1, callTimeoutMillis=10000, firstInvocationTimeMs=1560427012149, firstInvocationTime='2019-06-13 13:56:52.149', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}
	... 11 common frames omitted
2019-06-13 13:57:14.673 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 13:57:14.673 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-1] com.hazelcast.internal.cluster.impl.ClusterHeartbeatManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Resetting heartbeat timestamps because of huge system clock jump! Clock-Jump: 21547 ms, Heartbeat-Timeout: 10000 ms

2019-06-13 13:57:23.679 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.ClusterHeartbeatManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Resetting heartbeat timestamps because of huge system clock jump! Clock-Jump: 8006 ms, Heartbeat-Timeout: 10000 ms
2019-06-13 13:57:26.751 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=931901948, partitionId=0, replicaIndex=0, callId=40466, invocationTime=1560427046751 (2019-06-13 13:57:26.751), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012087, firstInvocationTime='2019-06-13 13:56:52.087', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 0, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.751 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=30743835, partitionId=1, replicaIndex=0, callId=40467, invocationTime=1560427046751 (2019-06-13 13:57:26.751), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 1, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.751 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=509242909, partitionId=2, replicaIndex=0, callId=40468, invocationTime=1560427046751 (2019-06-13 13:57:26.751), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 2, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.751 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1189167169, partitionId=3, replicaIndex=0, callId=40469, invocationTime=1560427046751 (2019-06-13 13:57:26.751), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 3, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.751 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=747576624, partitionId=4, replicaIndex=0, callId=40470, invocationTime=1560427046751 (2019-06-13 13:57:26.751), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 4, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.751 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=94101631, partitionId=5, replicaIndex=0, callId=40471, invocationTime=1560427046751 (2019-06-13 13:57:26.751), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 5, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.752 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1216105559, partitionId=6, replicaIndex=0, callId=40472, invocationTime=1560427046751 (2019-06-13 13:57:26.751), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 6, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.752 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=81002065, partitionId=7, replicaIndex=0, callId=40473, invocationTime=1560427046752 (2019-06-13 13:57:26.752), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 7, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.752 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1356928358, partitionId=8, replicaIndex=0, callId=40474, invocationTime=1560427046752 (2019-06-13 13:57:26.752), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 8, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.752 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=178491165, partitionId=9, replicaIndex=0, callId=40475, invocationTime=1560427046752 (2019-06-13 13:57:26.752), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012125, firstInvocationTime='2019-06-13 13:56:52.125', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 9, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:26.752 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=546792682, partitionId=10, replicaIndex=0, callId=40476, invocationTime=1560427046752 (2019-06-13 13:57:26.752), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=100, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012125, firstInvocationTime='2019-06-13 13:56:52.125', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 10, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
...
...
...
the same till partition 179
...
2019-06-13 13:57:34.959 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.HealthMonitor] com.hazelcast.internal.diagnostics.HealthMonitor - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] processors=8, physical.memory.total=15,9G, physical.memory.free=2,2G, swap.space.total=45,7G, swap.space.free=6,0G, heap.memory.used=213,0M, heap.memory.free=41,0M, heap.memory.total=254,0M, heap.memory.max=2,0G, heap.memory.used/total=83,87%, heap.memory.used/max=10,40%, minor.gc.count=190, minor.gc.time=1539ms, major.gc.count=0, major.gc.time=0ms, load.process=9,64%, load.system=6,06%, load.systemAverage=n/a thread.count=216, thread.peakCount=216, cluster.timeDiff=0, event.q.size=0, executor.q.async.size=0, executor.q.client.size=0, executor.q.query.size=0, executor.q.scheduled.size=0, executor.q.io.size=0, executor.q.system.size=0, executor.q.operations.size=0, executor.q.priorityOperation.size=0, operations.completed.count=206395, executor.q.mapLoad.size=0, executor.q.mapLoadAllKeys.size=0, executor.q.cluster.size=0, executor.q.response.size=0, operations.running.count=0, operations.pending.invocations.percentage=0,00%, operations.pending.invocations.count=135, proxy.count=0, clientEndpoint.count=0, connection.active.count=1, client.connection.count=0, connection.count=0
...
2019-06-13 13:57:37.287 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=931901948, partitionId=0, replicaIndex=0, callId=44516, invocationTime=1560427057287 (2019-06-13 13:57:37.287), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012087, firstInvocationTime='2019-06-13 13:56:52.087', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 0, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.287 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=30743835, partitionId=1, replicaIndex=0, callId=44517, invocationTime=1560427057287 (2019-06-13 13:57:37.287), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 1, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.288 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=509242909, partitionId=2, replicaIndex=0, callId=44518, invocationTime=1560427057287 (2019-06-13 13:57:37.287), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 2, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.288 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1189167169, partitionId=3, replicaIndex=0, callId=44519, invocationTime=1560427057288 (2019-06-13 13:57:37.288), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 3, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.288 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=747576624, partitionId=4, replicaIndex=0, callId=44520, invocationTime=1560427057288 (2019-06-13 13:57:37.288), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 4, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.292 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=94101631, partitionId=5, replicaIndex=0, callId=44522, invocationTime=1560427057292 (2019-06-13 13:57:37.292), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 5, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.292 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1216105559, partitionId=6, replicaIndex=0, callId=44523, invocationTime=1560427057292 (2019-06-13 13:57:37.292), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 6, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.292 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=81002065, partitionId=7, replicaIndex=0, callId=44524, invocationTime=1560427057292 (2019-06-13 13:57:37.292), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 7, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:57:37.292 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1356928358, partitionId=8, replicaIndex=0, callId=44525, invocationTime=1560427057292 (2019-06-13 13:57:37.292), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 8, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
...
...
2019-06-13 13:57:55.341 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.generic-operation.thread-2] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=51797, invocationTime=1560427075341 (2019-06-13 13:57:55.341), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=130, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 13:57:56.477 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=52209, invocationTime=1560427076477 (2019-06-13 13:57:56.477), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=140, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
...
2019-06-13 13:58:05.879 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=55847, invocationTime=1560427085879 (2019-06-13 13:58:05.879), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=160, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 13:58:07.923 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=56406, invocationTime=1560427087923 (2019-06-13 13:58:07.923), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=170, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=931901948, partitionId=0, replicaIndex=0, callId=56666, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012087, firstInvocationTime='2019-06-13 13:56:52.087', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 0, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=30743835, partitionId=1, replicaIndex=0, callId=56667, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 1, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=509242909, partitionId=2, replicaIndex=0, callId=56668, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 2, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1189167169, partitionId=3, replicaIndex=0, callId=56669, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 3, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=747576624, partitionId=4, replicaIndex=0, callId=56670, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 4, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=94101631, partitionId=5, replicaIndex=0, callId=56671, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 5, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1216105559, partitionId=6, replicaIndex=0, callId=56672, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 6, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=81002065, partitionId=7, replicaIndex=0, callId=56673, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 7, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1356928358, partitionId=8, replicaIndex=0, callId=56674, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012124, firstInvocationTime='2019-06-13 13:56:52.124', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 8, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=178491165, partitionId=9, replicaIndex=0, callId=56675, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012125, firstInvocationTime='2019-06-13 13:56:52.125', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 9, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=546792682, partitionId=10, replicaIndex=0, callId=56676, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012125, firstInvocationTime='2019-06-13 13:56:52.125', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 10, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.902 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1001207775, partitionId=11, replicaIndex=0, callId=56677, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012125, firstInvocationTime='2019-06-13 13:56:52.125', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 11, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.903 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1665097705, partitionId=12, replicaIndex=0, callId=56678, invocationTime=1560427088902 (2019-06-13 13:58:08.902), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012125, firstInvocationTime='2019-06-13 13:56:52.125', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 12, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
2019-06-13 13:58:08.929 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.InvocationMonitorThread] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.map.impl.query.QueryPartitionOperation{serviceName='hz:impl:mapService', identityHash=1978859508, partitionId=13, replicaIndex=0, callId=56680, invocationTime=1560427088929 (2019-06-13 13:58:08.929), waitTimeout=-1, callTimeout=60000, name=jobMetadataStorage}, tryCount=250, tryPauseMillis=500, invokeCount=220, callTimeoutMillis=60000, firstInvocationTimeMs=1560427012125, firstInvocationTime='2019-06-13 13:56:52.125', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=null, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 13, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
...
2019-06-13 13:58:16.427 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=59897, invocationTime=1560427096427 (2019-06-13 13:58:16.427), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=190, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 13:58:19.442 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.generic-operation.thread-1] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=60724, invocationTime=1560427099441 (2019-06-13 13:58:19.441), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=200, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
com.hazelcast.spi.exception.WrongTargetException: WrongTarget! this: [10.80.32.29]:5701, target: null, partitionId: 0, replicaIndex: 0, operation: com.hazelcast.map.impl.query.QueryPartitionOperation, service: hz:impl:mapService
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.newTargetNullException(Invocation.java:640)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.initInvocationTarget(Invocation.java:250)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvoke(Invocation.java:547)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.access$300(Invocation.java:97)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation$InvocationRetryTask.run(Invocation.java:754)
	at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.resolve(InvocationFuture.java:127)
	at com.hazelcast.spi.impl.operationservice.impl.InvocationFuture.resolveAndThrowIfException(InvocationFuture.java:79)
	at com.hazelcast.spi.impl.AbstractInvocationFuture.get(AbstractInvocationFuture.java:162)
	at com.hazelcast.map.impl.query.MapQueryEngineImpl.addResultsOfPredicate(MapQueryEngineImpl.java:195)
	at com.hazelcast.map.impl.query.MapQueryEngineImpl.doRunQueryOnPartitionThreads(MapQueryEngineImpl.java:181)
	at com.hazelcast.map.impl.query.MapQueryEngineImpl.runQueryOnAllPartitions(MapQueryEngineImpl.java:128)
	at com.hazelcast.map.impl.query.MapQueryEngineImpl.execute(MapQueryEngineImpl.java:87)
	at com.hazelcast.map.impl.proxy.MapProxySupport.executeQueryInternal(MapProxySupport.java:1258)
	at com.hazelcast.map.impl.proxy.MapProxySupport.executeQueryInternal(MapProxySupport.java:1234)
	at com.hazelcast.map.impl.proxy.MapProxyImpl.executePredicate(MapProxyImpl.java:630)
	at com.hazelcast.map.impl.proxy.MapProxyImpl.values(MapProxyImpl.java:625)
	at com.hazelcast.map.impl.proxy.MapProxyImpl.values(MapProxyImpl.java:619)

...
2019-06-13 13:59:50.791 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.generic-operation.thread-2] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61095, invocationTime=1560427190791 (2019-06-13 13:59:50.791), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=450, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 13:59:51.930 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61105, invocationTime=1560427191930 (2019-06-13 13:59:51.930), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=460, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 13:59:56.321 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61115, invocationTime=1560427196321 (2019-06-13 13:59:56.321), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=470, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:00:01.254 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:00:01.255 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-25] com.hazelcast.internal.cluster.impl.ClusterHeartbeatManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] System clock apparently jumped from 2019-06-13 13:57:46.193 to 2019-06-13 14:00:01.254 since last heartbeat (+134061 ms)
2019-06-13 14:00:01.255 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-25] com.hazelcast.internal.cluster.impl.ClusterHeartbeatManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Resetting heartbeat timestamps because of huge system clock jump! Clock-Jump: 134061 ms, Heartbeat-Timeout: 10000 ms
2019-06-13 14:00:01.333 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61125, invocationTime=1560427067272 (2019-06-13 13:57:47.272), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=480, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:00:03.375 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61135, invocationTime=1560427069314 (2019-06-13 13:57:49.314), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=490, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:00:05.257 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.HealthMonitor] com.hazelcast.internal.diagnostics.HealthMonitor - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] processors=8, physical.memory.total=15,9G, physical.memory.free=2,2G, swap.space.total=45,7G, swap.space.free=6,1G, heap.memory.used=203,9M, heap.memory.free=50,1M, heap.memory.total=254,0M, heap.memory.max=2,0G, heap.memory.used/total=80,27%, heap.memory.used/max=9,95%, minor.gc.count=192, minor.gc.time=1558ms, major.gc.count=0, major.gc.time=0ms, load.process=0,06%, load.system=7,04%, load.systemAverage=n/a thread.count=204, thread.peakCount=218, cluster.timeDiff=-134061, event.q.size=0, executor.q.async.size=0, executor.q.client.size=0, executor.q.query.size=0, executor.q.scheduled.size=0, executor.q.io.size=0, executor.q.system.size=0, executor.q.operations.size=0, executor.q.priorityOperation.size=0, operations.completed.count=206811, executor.q.mapLoad.size=0, executor.q.mapLoadAllKeys.size=0, executor.q.cluster.size=0, executor.q.response.size=0, operations.running.count=0, operations.pending.invocations.percentage=0,00%, operations.pending.invocations.count=1, proxy.count=0, clientEndpoint.count=0, connection.active.count=1, client.connection.count=0, connection.count=0
2019-06-13 14:00:06.865 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.generic-operation.thread-1] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61145, invocationTime=1560427072804 (2019-06-13 13:57:52.804), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=500, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:00:11.873 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61155, invocationTime=1560427077812 (2019-06-13 13:57:57.812), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=510, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:00:14.889 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61165, invocationTime=1560427080828 (2019-06-13 13:58:00.828), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=520, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:00:17.404 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61175, invocationTime=1560427083343 (2019-06-13 13:58:03.343), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=530, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
...
NODE CONNECTED BACK TO NETWORK
...
2019-06-13 14:01:12.626 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61325, invocationTime=1560427138565 (2019-06-13 13:58:58.565), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=680, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:01:13.288 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-27] com.hazelcast.internal.cluster.impl.ClusterHeartbeatManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Resetting heartbeat timestamps because of huge system clock jump! Clock-Jump: 66532 ms, Heartbeat-Timeout: 10000 ms
2019-06-13 14:01:13.294 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-7] com.hazelcast.nio.tcp.TcpIpConnectionManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Established socket connection between /10.80.32.29:43777 and /10.80.32.241:5701
2019-06-13 14:01:13.305 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-20] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.308 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-3] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.308 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-7] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.309 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-3] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.310 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-3] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.315 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-16] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.316 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-16] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.317 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-27] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:13.317 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.ClusterJoinManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] We should merge to [10.80.32.241]:5701, because their data member count is bigger than ours [2 > 1]
2019-06-13 14:01:13.317 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.cluster.impl.TcpIpJoiner - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] [10.80.32.29]:5701 is merging [tcp/ip] to [10.80.32.241]:5701
2019-06-13 14:01:13.510 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Locking cluster state. Initiator: [10.80.32.29]:5701, lease-time: 60000
2019-06-13 14:01:13.510 +02:00 ERROR [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
java.lang.IllegalStateException: Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.checkMigrationsAndPartitionStateVersion(ClusterStateManager.java:269)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterState(ClusterStateManager.java:212)
	at com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp.run(LockClusterStateOp.java:77)
	at com.hazelcast.spi.Operation.call(Operation.java:148)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.call(OperationRunnerImpl.java:202)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.run(OperationRunnerImpl.java:191)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.run(OperationExecutorImpl.java:406)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.runOrExecute(OperationExecutorImpl.java:433)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvokeLocal(Invocation.java:581)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvoke(Invocation.java:566)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke0(Invocation.java:525)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke(Invocation.java:215)
	at com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl.invokeOnTarget(OperationServiceImpl.java:321)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterStateOnAllMembers(ClusterStateManager.java:413)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:367)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:345)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:854)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:849)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.prepareClusterState(AbstractJoiner.java:335)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.startClusterMerge(AbstractJoiner.java:280)
	at com.hazelcast.cluster.impl.TcpIpJoiner.searchForOtherClusters(TcpIpJoiner.java:523)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.searchForOtherClusters(SplitBrainHandler.java:75)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.run(SplitBrainHandler.java:42)
	at com.hazelcast.spi.impl.executionservice.impl.DelegateAndSkipOnConcurrentExecutionDecorator$DelegateDecorator.run(DelegateAndSkipOnConcurrentExecutionDecorator.java:66)
	at com.hazelcast.util.executor.CachedExecutorServiceDelegate$Worker.run(CachedExecutorServiceDelegate.java:227)
	at com.hazelcast.util.executor.HazelcastManagedThread.executeRun(HazelcastManagedThread.java:64)
	at com.hazelcast.util.executor.HazelcastManagedThread.run(HazelcastManagedThread.java:80)
2019-06-13 14:01:13.518 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.RollbackClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Rolling back cluster state! Initiator: [10.80.32.29]:5701
2019-06-13 14:01:13.518 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.cluster.impl.TcpIpJoiner - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] While changing cluster state to FROZEN! java.lang.IllegalStateException: Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
2019-06-13 14:01:13.781 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.internal.cluster.impl.ClusterJoinManager - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] We should merge to [10.80.32.241]:5701, because their data member count is bigger than ours [2 > 1]
2019-06-13 14:01:13.787 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.event-2] net.gmc.nuc.core.datagrid.hzl.runtime.HazelcastQuorumListener - Received quorum event: QuorumEvent{threshold=0, currentMembers=com.hazelcast.internal.cluster.impl.MemberSelectingCollection@4160b54f, presence=false}
2019-06-13 14:01:14.519 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Locking cluster state. Initiator: [10.80.32.29]:5701, lease-time: 60000
2019-06-13 14:01:14.520 +02:00 ERROR [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
java.lang.IllegalStateException: Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.checkMigrationsAndPartitionStateVersion(ClusterStateManager.java:269)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterState(ClusterStateManager.java:212)
	at com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp.run(LockClusterStateOp.java:77)
	at com.hazelcast.spi.Operation.call(Operation.java:148)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.call(OperationRunnerImpl.java:202)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.run(OperationRunnerImpl.java:191)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.run(OperationExecutorImpl.java:406)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.runOrExecute(OperationExecutorImpl.java:433)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvokeLocal(Invocation.java:581)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvoke(Invocation.java:566)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke0(Invocation.java:525)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke(Invocation.java:215)
	at com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl.invokeOnTarget(OperationServiceImpl.java:321)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterStateOnAllMembers(ClusterStateManager.java:413)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:367)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:345)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:854)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:849)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.prepareClusterState(AbstractJoiner.java:335)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.startClusterMerge(AbstractJoiner.java:280)
	at com.hazelcast.cluster.impl.TcpIpJoiner.searchForOtherClusters(TcpIpJoiner.java:523)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.searchForOtherClusters(SplitBrainHandler.java:75)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.run(SplitBrainHandler.java:42)
	at com.hazelcast.spi.impl.executionservice.impl.DelegateAndSkipOnConcurrentExecutionDecorator$DelegateDecorator.run(DelegateAndSkipOnConcurrentExecutionDecorator.java:66)
	at com.hazelcast.util.executor.CachedExecutorServiceDelegate$Worker.run(CachedExecutorServiceDelegate.java:227)
	at com.hazelcast.util.executor.HazelcastManagedThread.executeRun(HazelcastManagedThread.java:64)
	at com.hazelcast.util.executor.HazelcastManagedThread.run(HazelcastManagedThread.java:80)
2019-06-13 14:01:14.520 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.RollbackClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Rolling back cluster state! Initiator: [10.80.32.29]:5701
2019-06-13 14:01:14.520 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.cluster.impl.TcpIpJoiner - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] While changing cluster state to FROZEN! java.lang.IllegalStateException: Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
2019-06-13 14:01:15.144 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.priority-generic-operation.thread-0] com.hazelcast.spi.impl.operationservice.impl.Invocation - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Retrying invocation: Invocation{op=com.hazelcast.internal.partition.operation.PromotionCommitOperation{serviceName='hz:core:partitionService', identityHash=1885059854, partitionId=-1, replicaIndex=0, callId=61341, invocationTime=1560427141083 (2019-06-13 13:59:01.083), waitTimeout=-1, callTimeout=10000}, tryCount=2147483647, tryPauseMillis=500, invokeCount=690, callTimeoutMillis=10000, firstInvocationTimeMs=1560427030176, firstInvocationTime='2019-06-13 13:57:10.176', lastHeartbeatMillis=0, lastHeartbeatTime='1970-01-01 01:00:00.000', target=[10.80.32.29]:5701, pendingResponse={VOID}, backupsAcksExpected=0, backupsAcksReceived=0, connection=null}, Reason: com.hazelcast.spi.exception.RetryableHazelcastException: Another promotion is being run currently. This is only expected when promotion is retried to an unresponsive destination.
2019-06-13 14:01:15.520 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Locking cluster state. Initiator: [10.80.32.29]:5701, lease-time: 60000
2019-06-13 14:01:15.520 +02:00 ERROR [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
java.lang.IllegalStateException: Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.checkMigrationsAndPartitionStateVersion(ClusterStateManager.java:269)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterState(ClusterStateManager.java:212)
	at com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp.run(LockClusterStateOp.java:77)
	at com.hazelcast.spi.Operation.call(Operation.java:148)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.call(OperationRunnerImpl.java:202)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.run(OperationRunnerImpl.java:191)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.run(OperationExecutorImpl.java:406)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.runOrExecute(OperationExecutorImpl.java:433)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvokeLocal(Invocation.java:581)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvoke(Invocation.java:566)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke0(Invocation.java:525)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke(Invocation.java:215)
	at com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl.invokeOnTarget(OperationServiceImpl.java:321)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterStateOnAllMembers(ClusterStateManager.java:413)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:367)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:345)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:854)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:849)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.prepareClusterState(AbstractJoiner.java:335)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.startClusterMerge(AbstractJoiner.java:280)
	at com.hazelcast.cluster.impl.TcpIpJoiner.searchForOtherClusters(TcpIpJoiner.java:523)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.searchForOtherClusters(SplitBrainHandler.java:75)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.run(SplitBrainHandler.java:42)
	at com.hazelcast.spi.impl.executionservice.impl.DelegateAndSkipOnConcurrentExecutionDecorator$DelegateDecorator.run(DelegateAndSkipOnConcurrentExecutionDecorator.java:66)
	at com.hazelcast.util.executor.CachedExecutorServiceDelegate$Worker.run(CachedExecutorServiceDelegate.java:227)
	at com.hazelcast.util.executor.HazelcastManagedThread.executeRun(HazelcastManagedThread.java:64)
	at com.hazelcast.util.executor.HazelcastManagedThread.run(HazelcastManagedThread.java:80)
2019-06-13 14:01:15.521 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.RollbackClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Rolling back cluster state! Initiator: [10.80.32.29]:5701
2019-06-13 14:01:15.521 +02:00 WARN  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.cluster.impl.TcpIpJoiner - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] While changing cluster state to FROZEN! java.lang.IllegalStateException: Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
2019-06-13 14:01:16.520 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Locking cluster state. Initiator: [10.80.32.29]:5701, lease-time: 60000
2019-06-13 14:01:16.520 +02:00 ERROR [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
java.lang.IllegalStateException: Still have pending migration tasks, cannot lock cluster state! New state: ClusterStateChange{type=class com.hazelcast.cluster.ClusterState, newState=FROZEN}, current state: ACTIVE
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.checkMigrationsAndPartitionStateVersion(ClusterStateManager.java:269)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterState(ClusterStateManager.java:212)
	at com.hazelcast.internal.cluster.impl.operations.LockClusterStateOp.run(LockClusterStateOp.java:77)
	at com.hazelcast.spi.Operation.call(Operation.java:148)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.call(OperationRunnerImpl.java:202)
	at com.hazelcast.spi.impl.operationservice.impl.OperationRunnerImpl.run(OperationRunnerImpl.java:191)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.run(OperationExecutorImpl.java:406)
	at com.hazelcast.spi.impl.operationexecutor.impl.OperationExecutorImpl.runOrExecute(OperationExecutorImpl.java:433)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvokeLocal(Invocation.java:581)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.doInvoke(Invocation.java:566)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke0(Invocation.java:525)
	at com.hazelcast.spi.impl.operationservice.impl.Invocation.invoke(Invocation.java:215)
	at com.hazelcast.spi.impl.operationservice.impl.OperationServiceImpl.invokeOnTarget(OperationServiceImpl.java:321)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.lockClusterStateOnAllMembers(ClusterStateManager.java:413)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:367)
	at com.hazelcast.internal.cluster.impl.ClusterStateManager.changeClusterState(ClusterStateManager.java:345)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:854)
	at com.hazelcast.internal.cluster.impl.ClusterServiceImpl.changeClusterState(ClusterServiceImpl.java:849)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.prepareClusterState(AbstractJoiner.java:335)
	at com.hazelcast.internal.cluster.impl.AbstractJoiner.startClusterMerge(AbstractJoiner.java:280)
	at com.hazelcast.cluster.impl.TcpIpJoiner.searchForOtherClusters(TcpIpJoiner.java:523)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.searchForOtherClusters(SplitBrainHandler.java:75)
	at com.hazelcast.internal.cluster.impl.SplitBrainHandler.run(SplitBrainHandler.java:42)
	at com.hazelcast.spi.impl.executionservice.impl.DelegateAndSkipOnConcurrentExecutionDecorator$DelegateDecorator.run(DelegateAndSkipOnConcurrentExecutionDecorator.java:66)
	at com.hazelcast.util.executor.CachedExecutorServiceDelegate$Worker.run(CachedExecutorServiceDelegate.java:227)
	at com.hazelcast.util.executor.HazelcastManagedThread.executeRun(HazelcastManagedThread.java:64)
	at com.hazelcast.util.executor.HazelcastManagedThread.run(HazelcastManagedThread.java:80)

```
Then exception "Still have pending migration tasks, cannot lock cluster state!" was still occuring in combination with message: "Remaining migration tasks in queue => 1" ..filtered log:
```
2019-06-13 14:01:24.184 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-15] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:39.109 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:01:54.103 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:02:09.096 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:02:24.091 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:02:39.086 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:02:54.080 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:03:09.074 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:03:24.068 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-21] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:03:39.062 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-21] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:03:54.057 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:04:09.053 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-21] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:04:24.046 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:04:39.041 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:04:54.035 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-21] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:05:09.029 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:05:24.023 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:05:39.018 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:05:54.012 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-9] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:06:09.006 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:06:24.004 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:06:39.004 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:06:54.003 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:07:09.004 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:07:24.003 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:07:39.003 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:07:54.002 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:08:09.002 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:08:24.001 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:08:39.001 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:08:54.001 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:09:09.000 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:09:24.001 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:09:39.000 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:09:53.999 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:10:08.999 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:10:23.999 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:10:39.000 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:10:53.999 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:11:08.999 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:11:23.999 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:11:38.999 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:11:53.998 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:12:08.998 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:12:23.997 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:12:38.998 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:12:53.997 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:13:08.997 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:13:23.998 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:13:38.996 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:13:53.997 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:14:08.996 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:14:23.996 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:14:38.995 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:14:53.995 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:15:08.996 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:15:23.995 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-5] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:15:38.994 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:15:53.996 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:16:08.995 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:16:23.996 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:16:38.994 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:16:53.994 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:17:08.993 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:17:23.993 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:17:38.993 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:17:53.994 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:18:08.992 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:18:23.995 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:18:39.004 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:18:54.011 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:19:09.018 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:19:24.026 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-17] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:19:39.031 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:19:54.040 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:20:09.048 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:20:24.054 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:20:39.061 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-27] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:20:54.070 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-27] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:21:09.077 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-27] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:21:24.084 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:21:39.091 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:21:54.098 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:22:09.105 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-27] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:22:24.113 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:22:39.121 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:22:54.127 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-3] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:23:09.134 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-36] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:23:24.140 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-3] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1
2019-06-13 14:23:39.141 +02:00 INFO  [hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.cached.thread-4] com.hazelcast.internal.partition.InternalPartitionService - [10.80.32.29]:5701 [Scaler-0bea9029-hzl-cluster}] [3.10.2] Remaining migration tasks in queue => 1

```

Detailed description of the **steps to reproduce** your issue.
1. Create a cluster with 3 member.
2. Disconnect 1 member from network
3. After 4 minutes connect disconnected member back to network
4. Member wont join cluster.


**Integration module version** (tomcat, jetty, spring, hibernate) + conf such as web.xml
Tomcat: 9.0.19
Spring: 5.1.7.RELEASE
Spring boot: 2.1.5.RELEASE
hibernate: 5.3.9.Final
camel: 2.23.1

We guess that error is in method commitPromotionsToDestination(Address destination, Collection<MigrationInfo> migrations) in MigrationManager.java.

```
try {
                if (logger.isFinestEnabled()) {
                    logger.finest("Sending commit operation to " + destination + " for " + migrations);
                }
                PartitionRuntimeState partitionState = partitionService.createPromotionCommitPartitionState(migrations);
                String destinationUuid = member.getUuid();
                PromotionCommitOperation op = new PromotionCommitOperation(partitionState, migrations, destinationUuid);
                Future<Boolean> future = nodeEngine.getOperationService()
                        .createInvocationBuilder(SERVICE_NAME, op, destination)
                        .setTryCount(Integer.MAX_VALUE)
                        .setCallTimeout(idempotentRetry ? memberHeartbeatTimeoutMillis : Long.MAX_VALUE).invoke();

                boolean result = future.get();
                if (logger.isFinestEnabled()) {
                    logger.finest("Promotion commit result " + result + " from " + destination
                            + " for migrations " + migrations);
                }
                return result;
            } catch (Throwable t) {
                logPromotionCommitFailure(destination, migrations, t);

                if (idempotentRetry && t.getCause() instanceof OperationTimeoutException) {
                    return commitPromotionsToDestination(destination, migrations);
                }
            }
```
**Our suspicion**
We have a suspicion that future.get() infinitely blocks MigrationThread and that is why MigrationQueue has an empty queue, but migrateTaskCount equals 1. It means, that afterTaskCompletion has not been called so far (because MigrationThread is blocked and cannot 'return' that task), which causes IllegalStateException("Still have pending migration tasks, cannot lock cluster state!") to be thrown each time node want to join existing cluster.

I made a thread dump of an application 3 hours later to find out, that the MigrationThread is still waiting in RepairPartitionTableTask.commitPromotionsToDestinations.

```
"hz._hzInstance_1_Scaler-0bea9029-hzl-cluster}.migration" #116 prio=5 os_prio=0 tid=0x00000000206e3800 nid=0x1d24 waiting on condition [0x0000000031c0e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
	at com.hazelcast.spi.impl.AbstractInvocationFuture.get(AbstractInvocationFuture.java:160)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.commitPromotionsToDestination(MigrationManager.java:1349)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.commitPromotionsToDestination(MigrationManager.java:1359)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.commitPromotionMigrations(MigrationManager.java:1229)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.promoteBackupsForMissingOwners(MigrationManager.java:1215)
	at com.hazelcast.internal.partition.impl.MigrationManager$RepairPartitionTableTask.run(MigrationManager.java:1156)
	at com.hazelcast.internal.partition.impl.MigrationThread.processTask(MigrationThread.java:121)
	at com.hazelcast.internal.partition.impl.MigrationThread.doRun(MigrationThread.java:98)
	at com.hazelcast.internal.partition.impl.MigrationThread.run(MigrationThread.java:67)
```

Unfortunately I do not have more information about what happened to that Future the thread is waiting for..
I mentioned, that there are some clock jumps in logs - I can not consider how much it is related with the issue.

Also I would like to point to recursive calling of commitPromotionsToDestination calling infinitely itself in case of timeout exceptions which can lead to StackOverFlowException or any other kind of memory leak.

**Suggested fix** in MigrationManager:1349
```
try {
      ...
      long timeout = idempotentRetry ? memberHeartbeatTimeoutMillis : Long.MAX_VALUE;
      boolean result = future.get(timeout, TimeUnit.MILLISECONDS);          
      if (logger.isFinestEnabled()) {
          logger.finest("Promotion commit result " + result + " from " + destination
                       + " for migrations " + migrations);
          }
      return result;
} catch(Trowable t) {
      logPromotionCommitFailure(destination, migrations, t);

      if (idempotentRetry && (t instanceof TimeoutException || t.getCause() instanceof OperationTimeoutException)) {
           return commitPromotionsToDestination(destination, migrations);
      }
}
```
.. And I would like to also convert recursive calling to non-recursive call.

Thank you very much for your response!