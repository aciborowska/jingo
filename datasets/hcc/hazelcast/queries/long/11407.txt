Hello,

We discovered an issue in Hazelcast 3.8.5 when using MapStores.
It seems that hcInstance.getMap(mapName) gets blocked when a new node joins and data is being loaded.
For us this is a serious problem since it might prevent the system from starting.

Here is a test that reproduces the issue:
```java
package test;

import com.hazelcast.config.Config;
import com.hazelcast.config.MapConfig;
import com.hazelcast.config.MapStoreConfig;
import com.hazelcast.config.XmlConfigBuilder;
import com.hazelcast.core.Hazelcast;
import com.hazelcast.core.HazelcastInstance;
import com.hazelcast.core.IMap;
import org.apache.log4j.BasicConfigurator;
import org.apache.log4j.Logger;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.atomic.AtomicInteger;

import static org.junit.Assert.fail;

/**
 * Test to ensure there is no deadlock when a new node joins during data loading.
 */
public class TestMapStore33 {

    private static final Logger logger = Logger.getLogger(TestMapStore33.class);

    private static final int preloadSize = 1000;

    private static final int writeDelaySeconds = 5;

    private static final AtomicInteger mapSize = new AtomicInteger(-1);

    private final String mapName = "map" + getClass().getSimpleName();

    private final InMemoryMapStoreSleepAndCount store = new InMemoryMapStoreSleepAndCount(300);

    private final ExecutorService executorService = Executors.newFixedThreadPool(3);

    private final List<HazelcastInstance> hazelcastInstances = new ArrayList<>();

    @Before
    public void setUp() throws Exception {
        BasicConfigurator.configure();
    }

    @After
    public void tearDown() {
        for (HazelcastInstance hazelcastInstance : hazelcastInstances) {
            hazelcastInstance.getLifecycleService().terminate();
        }
    }

    @Test
    public void testMapStoreLoad() throws InterruptedException {

        // load data in the store
        store.preload(preloadSize);

        // runnable that creates a new Hazelcast instance and checks the map size
        Runnable task = new Runnable() {
            @Override
            public void run() {
                HazelcastInstance hcInstance = Hazelcast.newHazelcastInstance(getConfig());
                hazelcastInstances.add(hcInstance);
                IMap<String, String> map = hcInstance.getMap(mapName);
                int size = map.size();
                mapSize.set(size);
            }
        };

        // start first Hazelcast instance
        executorService.submit(task);

        // wait 6s so that the first instance triggers data loading on the map
        Thread.sleep(6000);

        // start second Hazelcast instance
        executorService.submit(task);

        // wait at most 150s
        final long t0 = System.currentTimeMillis();
        while ((System.currentTimeMillis() - t0) < 150000) {
            if (mapSize.get() == preloadSize) {
                break;
            }
            Thread.sleep(1000);
            logger.info(String.format("Loaded keys: %s", store.getCountLoadedKeys()));
        }

        // check for errors
        if (mapSize.get() != preloadSize) {
            fail(String.format("Not all data loaded (%s != %s).", mapSize.get(), preloadSize));
        }
    }

    private Config getConfig() {

        // create shared hazelcast config
        final Config config = new XmlConfigBuilder().build();
        config.setProperty("hazelcast.logging.type", "log4j");

        // disable JMX to make sure lazy loading works asynchronously
        config.setProperty("hazelcast.jmx", "false");

        // get map config
        MapConfig mapConfig = config.getMapConfig(mapName);

        // configure map store
        MapStoreConfig mapStoreConfig = new MapStoreConfig();
        mapStoreConfig.setEnabled(true);
        mapStoreConfig.setInitialLoadMode(MapStoreConfig.InitialLoadMode.EAGER);
        mapStoreConfig.setWriteDelaySeconds(writeDelaySeconds);
        mapStoreConfig.setClassName(null);
        mapStoreConfig.setImplementation(store);
        mapConfig.setMapStoreConfig(mapStoreConfig);

        return config;
    }

}

package test;

import com.hazelcast.core.MapStore;

import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;

public class InMemoryMapStoreSleepAndCount implements MapStore<String, String> {

    private final ConcurrentHashMap<String, String> store = new ConcurrentHashMap<>();

    private final int msPerLoad;

    private final AtomicInteger countLoadedKeys = new AtomicInteger(0);

    // ----------------------------------------------------------- construction

    public InMemoryMapStoreSleepAndCount(int msPerLoad) {
        this.msPerLoad = msPerLoad;
    }

    public void preload(int size) {
        for (int i = 0; i < size; i++) {
            store.put("k" + i, "v" + i);
        }
    }

    // ---------------------------------------------------------------- getters

    public int getCountLoadedKeys() {
        return countLoadedKeys.get();
    }

    // ----------------------------------------------------- MapStore interface

    @Override
    public String load(String key) {
        if (msPerLoad > 0) {
            try {
                Thread.sleep(msPerLoad);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        countLoadedKeys.incrementAndGet();
        return store.get(key);
    }

    @Override
    public Map<String, String> loadAll(Collection<String> keys) {
        List<String> keysList = new ArrayList<>(keys);
        Collections.sort(keysList);

        Map<String, String> result = new HashMap<>();
        for (String key : keys) {

            if (msPerLoad > 0) {
                try {
                    Thread.sleep(msPerLoad);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }

            String value = store.get(key);
            if (value != null) {
                result.put(key, value);
            }
        }

        countLoadedKeys.addAndGet(keys.size());
        return result;
    }

    @Override
    public Set<String> loadAllKeys() {
        Set<String> result = new HashSet<>(store.keySet());
        List<String> resultList = new ArrayList<>(result);
        Collections.sort(resultList);
        return result;
    }

    @Override
    public void store(String key, String value) {
        store.put(key, value);
    }

    @Override
    public void storeAll(Map<String, String> map) {
        store.putAll(map);
    }

    @Override
    public void delete(String key) {
        store.remove(key);
    }

    @Override
    public void deleteAll(Collection<String> keys) {
        List<String> keysList = new ArrayList<>(keys);
        Collections.sort(keysList);
        for (String key : keys) {
            store.remove(key);
        }
    }

}

```

Could you please check this?
Is there a workaround to avoid this issue in 3.8.5?

Thanks,
Ruxandra