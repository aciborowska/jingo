
Hello,
I tried the following use case. I have some questions regarding behaviour of re-execution of tasks in  case of node failure.

[https://github.com/shalakhansidmul/hazelcast_test](https://github.com/shalakhansidmul/hazelcast_test)
In the provided example, there are 4 tasks:
SumTask, PutSumInAMapTask, SquareTask, PrintTheSquareTask.
All are HazelcastInstanceAware.
Order of execution:

Node1 will submit Sumtask to the executor.
Just before returning, Sumtask will submit PutSumInAMapTask to the executor.
Just before returning, PutSumInAMapTask will submit SquareTask to the executor.
Just before returning, SquareTask will submit PrintThe SquareTask to the executor.
There are 4 nodes in my Hazelcast cluster.
Steps:
Start the MasterMember(Node1) and three SlaveMembers(Node2,Node3,Node4) .
Observation:
SumTask submitted from node1. It executes on Node2
It submits PutSumInAMapTask and returns.
Randomly, PutSumInAMapTask also executes on Node2.
While the task is still running, I kill Node2.
The Hazelcast cluster repartitions the data and re-executes SumTask and PutSumInAMapTask on Node3.
Why does it execute SumTask even when it is completed?
It should ideally just resume/restart PutSumInAMapTask , right?