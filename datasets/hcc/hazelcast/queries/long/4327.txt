What version of Stabilizer ?

```
    more nohup-2014-12-18__13_57_42.out
INFO  13:56:58 Hazelcast Stabilizer Provisioner
INFO  13:56:58 Version: 0.4-SNAPSHOT, Commit: d632526, Build Time: 16.12.2014 @ 19:12:20 UTC
INFO  13:56:58 STABILIZER_HOME: /home/danny/hazelcast-stabilizer-0.4-SNAPSHOT
INFO  13:56:59 Loading stabilizer.properties: /disk1/danny/large-longTimeOut/stabilizer.properties
INFO  13:56:59 Current number of machines: 10
INFO  13:56:59 Desired number of machines: 10
INFO  13:56:59 Ignoring spawn machines, desired number of machines already exists.
INFO  13:56:59 Hazelcast Stabilizer Provisioner
INFO  13:56:59 Version: 0.4-SNAPSHOT, Commit: d632526, Build Time: 16.12.2014 @ 19:12:20 UTC
```

which matches with 

```
[danny@ip-10-72-134-107 hazelcast-stabilizer]$ git branch
* master

[danny@ip-10-72-134-107 hazelcast-stabilizer]$ git log
commit d6325262ad10c2b7d353f2f6125c09d70e25c2a9
Merge: 37dc5f3 6154016
Author: Jaromir Hamala <jaromir.hamala@gmail.com>
Date:   Tue Dec 16 15:56:08 2014 +0000

    Merge pull request #443 from hasancelik/queryBasicTest

    SqlPredicateBasicTest
```

What version of Hazelcast ? 
a member worker.log shows

```
INFO  2014-12-18 13:57:50,146 [main] com.hazelcast.system: [10.142.200.185]:5701 [workers] [3.4] Hazelcast 3.4 (20141216 - 8e85f3c) starting at Address[10.142.200.185]:5701
```

which matches with the in git info

```
[danny@ip-10-72-134-107 hazelcast]$ git branch
  3.1.8
  3.3.1
* 3.4
  fix/3.3/evictOnMerge
  maintenance-3.x
  master
  maxSize
[danny@ip-10-72-134-107 hazelcast]$ git log
commit 8e85f3cd74bfd3c06a9bf82171cea1933e04ea22
Author: Serkan Ã–ZAL <serkanozal86@hotmail.com>
Date:   Mon Dec 15 16:42:33 2014 +0200

    "Configuring Hi-Density Memory Store" section added to "Storage" documentation
```

What Test included

```
grep "Running T" nohup-2014-12-18__13_57_42.out
Running Test : MapTransactionTest
Running Test : MapTTL
Running Test : TxnQ
Running Test : MapEntryListenerTest
Running Test : iCacheListener
Running Test : iCacheEP
Running Test : QueueTest
Running Test : MapCasTest
Running Test : MapEntryProc
Running Test : MaxSizeMap
Running Test : MapLockTest
Running Test : MapPred
Running Test : MapStore1
Running Test : iCacheCreateDestroy
Running Test : iCacheCreate
Running Test : iCacheCas
Running Test : expir
Running Test : txnCon
Running Test : icacheMaxSmall
Running Test : lockConflict
Running Test : icacheMaxLarge
Running Test : icacheMaxMediume
Running Test : iCacheMangle
Running Test : iCacheTtl
Running Test : iCacheStr
```

From the Stabilizer output Reported this exception 

```
INFO  14:20:05 iCacheEP             Running 00d 00h 21m 00s   0.73% complete
WARN  14:20:06 Failure #1  client:10.203.167.185 Worker exception[com.hazelcast.nio.serialization.HazelcastSerializationException: java.io.UTFDataFormatException]
```

The Fail

```
more failures-2014-12-18__13_57_42.txt
Failure[
   message='Worked ran into an unhandled exception'
   type='Worker exception'
   agentAddress=10.203.167.185
   time=Thu Dec 18 14:20:06 UTC 2014
   workerAddress=client:10.203.167.185
   workerId=worker-10.203.167.185-4-client
   test=TestCase{
          id=MapPred
        , class=com.hazelcast.stabilizer.tests.map.MapPredicateTest
        , basename=MapPred
        , destroyProb=0
        , keyCount=3000
        , pagePred=0.25
        , predicateBuilder=0.25
        , sqlString=0.25
        , threadCount=3
        , updateEmployee=0.25
    }
   cause=com.hazelcast.nio.serialization.HazelcastSerializationException: java.io.UTFDataFormatException
    at com.hazelcast.nio.serialization.SerializationServiceImpl.handleException(SerializationServiceImpl.java:419)
    at com.hazelcast.nio.serialization.SerializationServiceImpl.readObject(SerializationServiceImpl.java:315)
    at com.hazelcast.nio.serialization.ByteArrayObjectDataInput.readObject(ByteArrayObjectDataInput.java:439)
    at com.hazelcast.query.PagingPredicate.readData(PagingPredicate.java:329)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:111)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:39)
    at com.hazelcast.nio.serialization.StreamSerializerAdapter.read(StreamSerializerAdapter.java:44)
    at com.hazelcast.nio.serialization.SerializationServiceImpl.readObject(SerializationServiceImpl.java:309)
    at com.hazelcast.nio.serialization.ByteArrayObjectDataInput.readObject(ByteArrayObjectDataInput.java:439)
    at com.hazelcast.map.impl.operation.QueryOperation.readInternal(QueryOperation.java:197)
    at com.hazelcast.spi.Operation.readData(Operation.java:299)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:111)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:39)
    at com.hazelcast.nio.serialization.StreamSerializerAdapter.toObject(StreamSerializerAdapter.java:65)
    at com.hazelcast.nio.serialization.SerializationServiceImpl.toObject(SerializationServiceImpl.java:260)
    at com.hazelcast.spi.impl.NodeEngineImpl.toObject(NodeEngineImpl.java:186)
    at com.hazelcast.spi.impl.BasicOperationService$OperationPacketHandler.loadOperation(BasicOperationService.java:638)
    at com.hazelcast.spi.impl.BasicOperationService$OperationPacketHandler.handle(BasicOperationService.java:621)
    at com.hazelcast.spi.impl.BasicOperationService$OperationPacketHandler.access$1500(BasicOperationService.java:614)
    at com.hazelcast.spi.impl.BasicOperationService$BasicDispatcherImpl.dispatch(BasicOperationService.java:566)
    at com.hazelcast.spi.impl.BasicOperationScheduler$OperationThread.process(BasicOperationScheduler.java:466)
    at com.hazelcast.spi.impl.BasicOperationScheduler$OperationThread.doRun(BasicOperationScheduler.java:458)
    at com.hazelcast.spi.impl.BasicOperationScheduler$OperationThread.run(BasicOperationScheduler.java:432)
    at ------ End remote and begin local stack-trace ------.(Unknown Source)
    at com.hazelcast.spi.impl.BasicInvocationFuture.resolveApplicationResponse(BasicInvocationFuture.java:387)
    at com.hazelcast.spi.impl.BasicInvocationFuture.resolveApplicationResponseOrThrowException(BasicInvocationFuture.java:320)
    at com.hazelcast.spi.impl.BasicInvocationFuture.get(BasicInvocationFuture.java:194)
    at com.hazelcast.spi.impl.BasicInvocationFuture.get(BasicInvocationFuture.java:173)
    at com.hazelcast.map.impl.client.AbstractMapQueryRequest.collectResults(AbstractMapQueryRequest.java:127)
    at com.hazelcast.map.impl.client.AbstractMapQueryRequest.invoke(AbstractMapQueryRequest.java:75)
    at com.hazelcast.client.impl.client.InvocationClientRequest.process(InvocationClientRequest.java:27)
    at com.hazelcast.client.impl.ClientEngineImpl$ClientPacketProcessor.processRequest(ClientEngineImpl.java:434)
    at com.hazelcast.client.impl.ClientEngineImpl$ClientPacketProcessor.run(ClientEngineImpl.java:353)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:745)
    at com.hazelcast.util.executor.HazelcastManagedThread.executeRun(HazelcastManagedThread.java:76)
    at com.hazelcast.util.executor.HazelcastManagedThread.run(HazelcastManagedThread.java:92)
    at ------ End remote and begin local stack-trace ------.(Unknown Source)
    at com.hazelcast.client.spi.impl.ClientCallFuture.resolveResponse(ClientCallFuture.java:201)
    at com.hazelcast.client.spi.impl.ClientCallFuture.get(ClientCallFuture.java:142)
    at com.hazelcast.client.spi.impl.ClientCallFuture.get(ClientCallFuture.java:118)
    at com.hazelcast.client.spi.ClientProxy.invoke(ClientProxy.java:151)
    at com.hazelcast.client.proxy.ClientMapProxy.values(ClientMapProxy.java:789)
    at com.hazelcast.stabilizer.tests.map.MapPredicateTest$Worker.run(MapPredicateTest.java:127)
    at java.lang.Thread.run(Thread.java:745)
    at com.hazelcast.stabilizer.tests.utils.ThreadSpawner$DefaultThread.run(ThreadSpawner.java:88)
Caused by: java.io.UTFDataFormatException
    at java.io.ObjectInputStream$BlockDataInputStream.readUTFSpan(ObjectInputStream.java:3118)
    at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3051)
    at java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:2864)
    at java.io.ObjectInputStream.readUTF(ObjectInputStream.java:1072)
    at java.io.ObjectStreamClass.readNonProxy(ObjectStreamClass.java:704)
    at java.io.ObjectInputStream.readClassDescriptor(ObjectInputStream.java:830)
    at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1601)
    at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
    at com.hazelcast.nio.serialization.DefaultSerializers$ObjectSerializer.read(DefaultSerializers.java:196)
    at com.hazelcast.nio.serialization.StreamSerializerAdapter.read(StreamSerializerAdapter.java:44)
    at com.hazelcast.nio.serialization.SerializationServiceImpl.readObject(SerializationServiceImpl.java:309)
    at com.hazelcast.nio.serialization.ByteArrayObjectDataInput.readObject(ByteArrayObjectDataInput.java:439)
    at com.hazelcast.query.PagingPredicate.readData(PagingPredicate.java:329)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:111)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:39)
    at com.hazelcast.nio.serialization.StreamSerializerAdapter.read(StreamSerializerAdapter.java:44)
    at com.hazelcast.nio.serialization.SerializationServiceImpl.readObject(SerializationServiceImpl.java:309)
    at com.hazelcast.nio.serialization.ByteArrayObjectDataInput.readObject(ByteArrayObjectDataInput.java:439)
    at com.hazelcast.map.impl.operation.QueryOperation.readInternal(QueryOperation.java:197)
    at com.hazelcast.spi.Operation.readData(Operation.java:299)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:111)
    at com.hazelcast.nio.serialization.DataSerializer.read(DataSerializer.java:39)
    at com.hazelcast.nio.serialization.StreamSerializerAdapter.toObject(StreamSerializerAdapter.java:65)
    at com.hazelcast.nio.serialization.SerializationServiceImpl.toObject(SerializationServiceImpl.java:260)
    at com.hazelcast.spi.impl.NodeEngineImpl.toObject(NodeEngineImpl.java:186)
    at com.hazelcast.spi.impl.BasicOperationService$OperationPacketHandler.loadOperation(BasicOperationService.java:638)
    at com.hazelcast.spi.impl.BasicOperationService$OperationPacketHandler.handle(BasicOperationService.java:621)
    at com.hazelcast.spi.impl.BasicOperationService$OperationPacketHandler.access$1500(BasicOperationService.java:614)
    at com.hazelcast.spi.impl.BasicOperationService$BasicDispatcherImpl.dispatch(BasicOperationService.java:566)
    at com.hazelcast.spi.impl.BasicOperationScheduler$OperationThread.process(BasicOperationScheduler.java:466)
    at com.hazelcast.spi.impl.BasicOperationScheduler$OperationThread.doRun(BasicOperationScheduler.java:458)
    at com.hazelcast.spi.impl.BasicOperationScheduler$OperationThread.run(BasicOperationScheduler.java:432)

]
```

Fatals from member logs

```
1  com.hazelcast.client.ClientEngine: [10.233.126.37]:5701 [workers] [3.4] While executing request: com.hazelcast.map.impl.client.MapQueryRequest@539fb9e -> java.io.UTFDataFormatException
      1  com.hazelcast.spi.impl.RemoteOperationExceptionHandler: java.io.UTFDataFormatException
      1  com.hazelcast.spi.OperationService: [10.203.167.185]:5701 [workers] [3.4] java.io.UTFDataFormatException
```

logging from MapEntryProcessorTest.

```
com.hazelcast.stabilizer.tests.map.MapEntryProcessorTest: MapPred OppCounter{predicateBuilderCount=1081, sqlStringCount=1077, pagePredCount=1076, updateEmployeCount=1143, destroyCount=0} from 149 worker threads
```

show how many opps it did before exception

This is the reason that the class name did not match the info printed, we Init the logger of MapPredicateTest with the wrong class 

```
public class MapPredicateTest {
    private final static ILogger log = Logger.getLogger(MapEntryProcessorTest.class);
```

Test settings

```
MapPred@class=com.hazelcast.stabilizer.tests.map.MapPredicateTest
MapPred@threadCount=3
MapPred@keyCount=3000
MapPred@predicateBuilder=0.25
MapPred@sqlString=0.25
MapPred@pagePred=0.25
MapPred@updateEmployee=0.25
MapPred@destroyProb=0
MapPred@basename=MapPred
```

test is designed to update the map values while the map is being queried 
