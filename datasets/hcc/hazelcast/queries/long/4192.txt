Hi.
I have hazelcast client and server. Client sends entry processors for ~3000 keys to server asynchroniously and waits for response through ExecutionCallback. I have logging in case of callback failure:

public void onFailure(Throwable t) {
        log.error("Failed recieve answer from server", t);
}

as sometimes we have GC problems on Hz server (G1 fails to Full gc and spends ~1 min on this), clients fail to recieve response and I get 3000 error logs for each request. At first look this does not seem disastrous as 3000 stacktraces (or 27000 for example - no matter) are not expected to take gigabytes on disk.

But the situation is different: the stacktraces look enormous (see attachment) and this swallowed 50Gb of logs for several minutes. Seems some kind of extra recursion occurs when building blocks for local and remote 

On the link see the part of single stacktrace (not full stacktrace) for single entry processor invocation - It already has > 1000 or rows, for my scenario (many entry processor invocations) that led to disaster - applications just wend out of disk

https://yadi.sk/i/KUNpkFjRd3o2A
