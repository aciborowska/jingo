Motivation:
In our scalability testing, we have a large number of clients watching for data changes. All of them fetch data immediately when a watch is fired. We found that GC consumes significant amount of CPU time in this scenario. In our prototype, we added packet caching for getData() request and found that GC time reduced by 40%. GC that we used is Concurrent Mark Sweep Collector. 

Design and Implementation:
Similar to our prototype, we plan to add packet caching for getData() request using LRU caching. The cache stores serializes response (data + stat) in form of ByteBuffer indexed by its pathname. The cache entry is invalidated when there is a set request that affect the data. 
The data structure that we plan to use for LRU cache is CacheBuilder http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/cache/CacheBuilder.html because it provides many tunable features that we try and use in the future. Currently, the eviction policy will be based on memory size. Otherwise, we can implement it using LinkedHashMap if we do not want to rely on external library.  