Right now, if one wants to write a SequenceFile from a custom StoreFunc he needs to declare it to be a OutputFormat<NullableText, NullableTuple>

Otherwise you get these exceptions:

ERROR org.apache.pig.tools.grunt.GruntParser - 
ERROR 2997: Unable to recreate exception from backed error: 
java.io.IOException: java.io.IOException: wrong key class: 
org.apache.hadoop.io.NullWritable is not class org.apache.pig.impl.io.NullableText

ERROR org.apache.pig.tools.grunt.GruntParser - 
ERROR 2997: Unable to recreate exception from backed error: 
java.io.IOException: java.io.IOException: wrong value class: 
org.apache.hadoop.io.BytesWritable is not class org.apache.pig.impl.io.NullableTuple



And stack trace:

java.io.IOException: java.io.IOException: wrong key class: org.apache.hadoop.io.NullWritable is not class org.apache.pig.impl.io.
NullableText
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.runPipeline(PigGenericMapReduce.java:464)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.processOnePackageOutput(PigGenericMapReduce.java:427)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.reduce(PigGenericMapReduce.java:399)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.reduce(PigGenericMapReduce.java:261)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:417)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:261)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.mapred.Child.main(Child.java:255)
Caused by: java.io.IOException: wrong key class: org.apache.hadoop.io.NullWritable is not class org.apache.pig.impl.io.NullableText
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:985)
	at org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat$1.write(SequenceFileOutputFormat.java:74)
	at mypackage.pig.BinStorage.putNext(BinStorage.java:75)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:139)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:98)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:587)
	at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.runPipeline(PigGenericMapReduce.java:462)
	... 11 more

