LoadConverter currently uses SparkContext.newAPIHadoopFile which won't work for non-filesystem based input sources, like HBase.

newAPIHadoopFile assumes a FileInputFormat and attempts to  verify this in the constructor, which fails for HBaseTableInputFormat (which is not a FileInputFormat)


  NewFileInputFormat.setInputPaths(job, path)

