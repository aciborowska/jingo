  What HCatLoader/HCatStorer puts in UDFContext is huge and if there are multiple of them in the pig script, the size of data sent to Tez AM is huge and also the size of data that Tez AM sends to tasks is huge causing RPC limit exceeded and OOM issues respectively.  If Pig serializes only part of the udfcontext that is required for each vertex, it will save a lot.  HCat folks are also looking up at cleaning what goes into the conf (it ends up serializing whole job conf, not just hive-site.xml) and moving out the common part to be shared by all hcat loaders and stores. 

Also looking at other options for faster and compact serialization. Will create separate jiras for that. Will use PIG-4653 to cleanup all other pig config other than udfcontext.