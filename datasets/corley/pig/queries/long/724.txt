Currently, PigStorage cannot treats the materialized string 123 as an integer with the value 123. If the user intended this to be the string 123, PigStorage cannot deal with it. This reasoning also applies to doubles. Due to this issue, maps that contain values which are of the same type but manifest the issue discussed at beginning of the paragraph, Pig throws its hands up at runtime.  An example to illustrate the problem will help.

In the example below a sample row in the data (map.txt) contains the following:

key01#35,key02#value01

When Pig tries to convert the stream to a map, it creates a Map<Object, Object> where the key is a string and the value is an integer. Running the script shown below, results in a run-time error.


grunt> a = load 'map.txt' as (themap: map[]);                    
grunt> b = filter a by (chararray)(themap#'key01') == 'hello';                  
grunt> dump b;

2009-03-18 15:19:03,773 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete
2009-03-18 15:19:28,797 [main] ERROR org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Map reduce job failed
2009-03-18 15:19:28,817 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1081: Cannot cast to chararray. Expected bytearray but received: int

 

There are two ways to resolve this issue:

1. Change the conversion routine for bytesToMap to return a map where the value is a bytearray and not the actual type. This change breaks backward compatibility
2. Introduce checks in POCast where conversions that are legal in the type checking world are allowed, i.e., run time checks will be made to check for compatible casts. In the above example, an int can be converted to a chararray and the cast will be made. If on the other hand, it was a chararray to int conversion then an exception will be thrown.