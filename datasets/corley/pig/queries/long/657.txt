The way to control the number of mappers in Hadoop has been to specify a mapred.min.split.size parameter in the job conf. For eg.  mapred.min.split.size=1073741824,mapred.map.tasks=10

However, even if this parameter is specified, Pig creates the number of mappers depending only on the number of blocks in the file. This is because the parameter is not used in the PigInputFormat.

The parameter can actually be extracted from the job conf object. So, one way of doing this would be to pass an handle to the job conf object to the PigInputFormat or the custom slicer.

